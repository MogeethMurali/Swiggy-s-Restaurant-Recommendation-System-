import pandas as pd

df = pd.read_csv(r'C:\Users\Mogeeth.M\Downloads\swiggy\env\swiggy.csv')

# Display initial data info
print("Initial dataset shape:", df.shape)
print("Missing values before cleaning:\n", df.isnull().sum())

df = df.drop_duplicates()

df = df.dropna()

# Display cleaned data info
print("Dataset shape after cleaning:", df.shape)
print("Missing values after cleaning:\n", df.isnull().sum())

# Save cleaned data
df.to_csv('cleaned_data.csv', index=False)
print("Cleaned data saved to cleaned_data.csv")


import pandas as pd
import numpy as np
import re
from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer
import pickle

df = pd.read_csv(r"C:\Users\Mogeeth.M\Downloads\swiggy\env\swiggy.csv")

# Remove duplicate rows
df.drop_duplicates(inplace=True)

def clean_cost(value):
    if pd.isna(value):
        return None
    cleaned = re.sub(r'[^\d.]', '', str(value))
    return cleaned if cleaned else None

def clean_rating_count(value):
    if pd.isna(value):
        return np.nan
    value = str(value).strip().lower()
    if 'too few' in value:
        return np.nan
    digits = re.findall(r'\d+', value)
    if digits:
        return int(digits[0])
    return np.nan


df['cost'] = df['cost'].apply(clean_cost)
df['rating_count'] = df['rating_count'].apply(clean_rating_count)

df['cost'] = pd.to_numeric(df['cost'], errors='coerce')
df['rating'] = pd.to_numeric(df['rating'], errors='coerce')
df['rating_count'] = pd.to_numeric(df['rating_count'], errors='coerce')

df = df[df['rating'] <= 20]

df['cost'].fillna(df['cost'].median(), inplace=True)
df['rating'].fillna(df['rating'].median(), inplace=True)
df['rating_count'].fillna(df['rating_count'].median(), inplace=True)


df['cuisine'] = df['cuisine'].fillna("").apply(lambda x: [c.strip().lower() for c in str(x).split(',') if c.strip()])

mlb = MultiLabelBinarizer()
cuisine_encoded = mlb.fit_transform(df['cuisine'])
cuisine_cols = mlb.classes_

ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
city_encoded = ohe.fit_transform(df[['city']])
city_cols = ohe.get_feature_names_out(['city'])


numerical_features = df[['rating', 'rating_count', 'cost']].values
numerical_cols = ['rating', 'rating_count', 'cost']


encoded_data = np.hstack((city_encoded, cuisine_encoded, numerical_features))
all_columns = list(city_cols) + list(cuisine_cols) + numerical_cols

encoded_df = pd.DataFrame(encoded_data, columns=all_columns)

encoded_df.to_csv(r"C:\Users\Mogeeth.M\Downloads\swiggy\env\encoded_data.csv", index=False)

with open(r"C:\Users\Mogeeth.M\Downloads\swiggy\env\encoder.pkl", "wb") as f:
    pickle.dump((ohe, mlb), f)

print("✅ Numeric columns cleaned and encoded data saved.")
print("✅ Encoders saved to encoder.pkl")


import pandas as pd
import numpy as np
import re
from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer
import pickle

# Load raw data
raw_path = r"C:\Users\Mogeeth.M\Downloads\swiggy\env\swiggy.csv"
df = pd.read_csv(raw_path)

# Remove duplicates
df.drop_duplicates(inplace=True)

# --- Cleaning Functions ---

def clean_cost(value):
    if pd.isna(value):
        return np.nan
    # Remove non-digit characters except dot
    cleaned = re.sub(r'[^\d.]', '', str(value))
    return float(cleaned) if cleaned else np.nan

def clean_rating_count(value):
    if pd.isna(value):
        return np.nan
    val_str = str(value).lower().strip()
    if 'too few' in val_str:
        return np.nan
    digits = re.findall(r'\d+', val_str)
    return int(digits[0]) if digits else np.nan

# Apply cleaning
df['cost'] = df['cost'].apply(clean_cost)
df['rating_count'] = df['rating_count'].apply(clean_rating_count)
df['rating'] = pd.to_numeric(df['rating'], errors='coerce')

# Remove invalid ratings (e.g., > 20 which is unrealistic)
df = df[df['rating'] <= 5]

# Fill missing numeric values with median
df['cost'].fillna(df['cost'].median(), inplace=True)
df['rating'].fillna(df['rating'].median(), inplace=True)
df['rating_count'].fillna(df['rating_count'].median(), inplace=True)

# Clean cuisine column: split by comma and strip spaces, convert to lowercase
df['cuisine'] = df['cuisine'].fillna("").apply(lambda x: [c.strip().lower() for c in x.split(',') if c.strip()])

# Save cleaned data for reference and display in app
cleaned_path = r"C:\Users\Mogeeth.M\Downloads\swiggy\env\cleaned_data.csv"
df.to_csv(cleaned_path, index=False)
print(f"✅ Cleaned data saved to {cleaned_path}")

# --- Encoding ---

# MultiLabelBinarizer for cuisine
mlb = MultiLabelBinarizer()
cuisine_encoded = mlb.fit_transform(df['cuisine'])
cuisine_cols = [f"cuisine_{c}" for c in mlb.classes_]

# OneHotEncoder for city
ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
city_encoded = ohe.fit_transform(df[['city']])
city_cols = ohe.get_feature_names_out(['city'])

# Numerical features
numerical_features = df[['rating', 'rating_count', 'cost']].values
numerical_cols = ['rating', 'rating_count', 'cost']

# Combine all features horizontally
encoded_data = np.hstack((city_encoded, cuisine_encoded, numerical_features))
all_columns = list(city_cols) + cuisine_cols + numerical_cols

# Create DataFrame for encoded data
encoded_df = pd.DataFrame(encoded_data, columns=all_columns)

# Save encoded dataset for recommendation engine
encoded_path = r"C:\Users\Mogeeth.M\Downloads\swiggy\env\encoded_data.csv"
encoded_df.to_csv(encoded_path, index=False)
print(f"✅ Encoded data saved to {encoded_path}")

# Save encoders to reuse in Streamlit app
encoder_path = r"C:\Users\Mogeeth.M\Downloads\swiggy\env\encoder.pkl"
with open(encoder_path, "wb") as f:
    pickle.dump((ohe, mlb), f)
print(f"✅ Encoders saved to {encoder_path}")
